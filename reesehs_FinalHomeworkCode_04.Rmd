---
title: "reesehs_FinalHomeworkCode_04"
author: "Reese Hotten-Somers"
date: "2023-11-01"
output: 
 html_document:
    theme: cosmo
    toc: yes
    toc_float:
      collapsed: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Question 1:

Write a simple R function, Z.prop.test(), that can perform one- or two-sample Z-tests for proportion data, using the following guidelines:
```{r}

z.prop.test <- function( p1, n1, p2 = NULL, n2 = NULL, p0, alternative = c("two.sided", "less", "greater"), conf.levels = 0.95) {
  if(((n1*p1)> 5 )|| (n1*(1-p1) > 5)){
    print("non-normal distribution in one sample setting")
  }
  if((n2*p2)> 5 || n2*(1-p2) > 5){
    print("non-normal distribution in two sample setting")
  } #the two previous if functions check for normal distribution and if non-normal prints out warning message
  if(is.null(p2) == TRUE || is.null(n2) == TRUE){
    z <- (p1-p0)/sqrt(p0 *(1-p0)/n1) #one sample z stat
    lower <- p1 - qnorm(0.95) * sqrt(p1 * (1 - p1)/n1)
    upper <- p1 + qnorm(0.95) * sqrt(p1 * (1 - p1)/n1)
    ci <- c(lower, upper) #confidence interval based around p1
    ci
#*C: i believe it is, yes!; whether it calculates correct within the function I am less sure about...
  
    if(alternative == "two.sided"){ 
       p <- 1 - pnorm(z, lower.tail = TRUE) + pnorm(z, lower.tail = FALSE) #          calculates two tailed p value
    }
    if(alternative == "less"){
      p <- pnorm(z, lower.tail = TRUE) #calculates lower tailed p value
    }
    if(alternative == "greater"){
      p <- pnorm(z, lower.tail = FALSE) #upper tail p value
    } #*C: don't forget the period in lower.tail above!
    return(list(z, p, ci))#returns z test, p value, and confidence interval calculated above
  }
  if(is.null(p2) == TRUE & is.null(n2) == TRUE){
   z <- (p1-p0)/sqrt(p0 *(1-p0)/n1) # one sample z stat
    if(alternative == "two.sided"){
       p <- 1 - pnorm(z, lower.tail = TRUE) + pnorm(z, lower.tail = FALSE)
    }
    if(alternative == "less"){
      p <- pnorm(z, lower.tail = TRUE)
    }
    if(alternative == "greater"){
      p <- pnorm(z, lowertail = FALSE)
    }
    lower <- p1 - qnorm(0.95) * sqrt(p1 * (1 - p1)/30)
    upper <- p1 + qnorm(0.95) * sqrt(p1 * (1 - p1)/30)
    ci <- c(lower, upper) #confidence interval based around p1 
    ci
     return(list(z, p, ci))#returns z test, p value, and confidence interval calculated above
  }

  if(!is.null(p2) & !is.null(n2)){
    pstar <- ((p0)/(n1 + n2)) #calculates pooled proportion 
    z <- (p2 - p1 - p0)/sqrt((pstar * (1 - pstar)) * (1/n1) + (1/n2)) #two sample z statistic 
    p <- 1 - pnorm(z, lower.tail = TRUE) + pnorm(z, lower.tail = FALSE) #two sided p valued
     
     upper <- (p1 -p2) + qnorm(0.95) + (sqrt((p1 * (1 - p1)/n1) + (p2 * (1-p2)/n2))) 
     lower <- (p1 -p2) - qnorm(0.95) + (sqrt((p1 * (1 - p1)/n1) + (p2 * (1-p2)/n2)))
     ci <- c(lower, upper) # calculates two side CI around p1 and p2
     ci
    return(list(z, p, ci)) #returns the z test, p value, and confidence interval given the above arguments and calculations
  }

#*C: i am not sure if this was referring to the whole chunk or the list function but if it is for list I can help! You can do return(list(estimate = z, p = p, ci=ci)), although you may have to play around with the variables a bit more since mine were a bit different when assigned! Hope that helps!
  }
```
*C: I know I had a lot of trouble with this and I would say you did an amazing job tackling everything! It is clear and makes sense each argument you are applying. While I am not sure how helpful my comments could be, I hoped they helped clear some of the function writing up :)

## Question 2:

The dataset from Kamilar and Cooper has in it a large number of variables related to life history and body size.  
```{r, preliminaries}
library(ggplot2)
library(curl)
library(ggpubr)
f <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/master/AN588_Fall23/KamilarAndCooperData.csv") #imports data from Kamilar/Cooper data
d <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = FALSE)  #reads data and creates data frame from it
head(d) #returns data frame
```

### Linear Regression for data

For this exercise, the end aim is to fit a simple linear regression model to predict longevity (MaxLongevity_m) measured in months from species’ brain size (Brain_Size_Species_Mean) measured in grams. Linear Regression for longevity~brain size
```{r, regression model}
#Fit the regression model and, using {ggplot2}, produce a scatter plot with the fitted line superimposed upon the data. Append the the fitted model equation to your plot 

nl <- lm(data = d, MaxLongevity_m~Brain_Size_Species_Mean) #creates linear model
summary(nl)


#plotting the data with linear model line
g <- ggplot(data = d, aes(x = Brain_Size_Species_Mean, y = MaxLongevity_m)) + geom_point() + geom_smooth(method = "lm", formula = y ~ x) + stat_regline_equation(label.x=30, label.y=790) +  stat_cor(aes(label=..rr.label..), label.x=30, label.y=750)
 #creates plot of linear regression with 95% regression shaft outline and regression line equation and r^2 value
g


#Identify and interpret the point estimate of the slope (β1), as well as the outcome of the test associated with the hypotheses H0: β1= 0; HA: β1 ≠ 0. Also, find a 90 percent CI for the slope (β1) parameter.

beta1 <- cor(d$MaxLongevity_m, d$Brain_Size_Species_Mean, use = "complete.obs") * sd(d$MaxLongevity_m, na.rm = TRUE)/sd(d$Brain_Size_Species_Mean, na.rm = TRUE) #returns slope of linear regression
beta1

beta0 <- mean(d$MaxLongevity_m, na.rm = TRUE) - beta1 * mean(d$Brain_Size_Species_Mean, na.rm = TRUE)
beta0 #gives intercept of linear regression


#Calculating CI
ci <- confint(nl, level = 0.90)  # using the results of lm() finds 90% confidence interval 
ci
# *C: nice job! I am pretty sure this does it


# Using your model, add lines for the 90 percent confidence and prediction interval bands on the plot and add a legend to differentiate between the lines.


h_hat <- predict(nl, newdata = data.frame(Brain_Size_Species_Mean = d$Brain_Size_Species_Mean)) #h_hat or y hat generates predicted y values from the linear regression nl and based on x values of Brain size species mean
df <- data.frame(cbind(d$Brain_Size_Species_Mean, d$MaxLongevity_m, h_hat))  #creates data frame of plot point and predicted points
names(df) <- c("x", "y", "yhat") #names the data columns
head(df)


ci <- predict(nl, newdata = data.frame(Brain_Size_Species_Mean = d$Brain_Size_Species_Mean), interval = "confidence",
    level = 0.95, )  # predicts CI for a predicted vector of values
head(ci)


df <- cbind(df, ci) #binds the list of CI values to dataframe
names(df) <- c("x", "y", "yhat", "CIfit", "CIlwr", "CIupr") #names the different columns containing CI values
head(df)


pi <- predict(nl, newdata = data.frame(Brain_Size_Species_Mean = d$Brain_Size_Species_Mean), interval = "prediction",
    level = 0.9)  # predicts PI values for the predicted vector of values
head(pi)

df <- cbind(df, pi)
names(df) <- c("x", "y", "yhat", "CIfit", "CIlwr", "CIupr", "PIfit", "PIlwr",
    "PIupr")
head(df)

colors <- c("PI" = "red", "CIfit" = "black", "CI" = "blue")
g <- ggplot(data = df, aes(x = x, y = y))+ geom_line(data = df, aes(x = x, y = PIlwr, color = "PI")) + geom_line(data = df, aes(x = x, y = PIupr, color = "PI")) + geom_point(alpha = 1/2) + geom_line(aes(x = x, y = CIfit, color = "CIfit")) + geom_line(aes(x = x, y = CIlwr, color = "CI")) + geom_line(aes(x = x, y = CIupr, colour = "CI")) + stat_regline_equation(label.x=30, label.y=790) +  stat_cor(aes(label=..rr.label..), label.x=30, label.y=750) + scale_color_manual(values = colors) #adds PI upper and lower lines as well as CI upper, fit, and lower lines to plot of predicted data
g


#Produce a point estimate and associated 90 percent PI for the longevity of a species whose brain weight is 800 gm. Do you trust the model to predict observations accurately for this value of the explanatory variable? Why or why not?

pe <- predict(nl, newdata = data.frame(Brain_Size_Species_Mean = 800))#one way of doing a point estimate
pe


ci <- predict(nl, newdata = data.frame(Brain_Size_Species_Mean = 800), interval = "confidence",
    level = 0.9)  # confidence interval for a single value
ci

pi <- predict(nl, newdata = data.frame(Brain_Size_Species_Mean = 800), interval = "prediction",
    level = 0.9)  # prediction interval for a single value
pi


```
I am not sure I trust this model completely given that the data the linear model is based off of is mainly under 200 grams. The prediction and confidence interval bands expand as brain size increases, especially after 300 so expecting a extremely acurate prediction for 800 grams is not something that I would trust.


*C: you did a really great job in this section commenting on each line of code to say what it gives you. i think it may benefit a reader who has no background if you explained what some variables mean, like yhat? Other than that, really excellent job adding everything to the plot and writing it out neatly.

### Linear Regression for log(longevity)~log(brain size):

```{r, make it a log}
#create some variables for 
brainlg <- log(d$Brain_Size_Species_Mean)
longlg <- log(d$MaxLongevity_m)

llm <- lm(data = d, longlg~brainlg) #creates linear model
summary(llm)
lg <- ggplot(data = d, aes(x = log(Brain_Size_Species_Mean), y = log(MaxLongevity_m))) + geom_point() + geom_smooth(method = "lm", formula = y ~ x) +stat_regline_equation(label.x=1, label.y= 6.45) +  stat_cor(aes(label=..rr.label..), label.x=1, label.y=6.2) #creates plot of linear regression with 95% regression shaft outline + equations for regression line and r^2 value
lg


#calculate beta 1
beta1 <- cor(log(d$MaxLongevity_m), log(d$Brain_Size_Species_Mean), use = "complete.obs") * sd(log(d$MaxLongevity_m), na.rm = TRUE)/sd(log(d$Brain_Size_Species_Mean), na.rm = TRUE) #returns slope of linear regression
beta1

#calculate beta 0
beta0 <- mean(log(d$MaxLongevity_m), na.rm = TRUE) - beta1 * mean(log(d$Brain_Size_Species_Mean), na.rm = TRUE)  #gives intercept of linear regression
beta0

#calculate confidence interval 
ci <- confint(llm, level = 0.90)  # using the results of lm(), confidence interval
ci


h_hat <- predict(llm, newdata = data.frame(brainlg = log(d$Brain_Size_Species_Mean)))
df <- data.frame(cbind(log(d$Brain_Size_Species_Mean)), (log(d$MaxLongevity_m)), h_hat)
names(df) <- c("x", "y", "yhat")
head(df)


ci <- predict(llm, newdata = data.frame(brainlg = log(d$Brain_Size_Species_Mean)), interval = "confidence",
    level = 0.9)  
head(ci)

df <- cbind(df, ci)
names(df) <- c("x", "y", "yhat", "CIfit", "CIlwr", "CIupr")
head(df)

pi <- predict(llm, newdata = data.frame(brainlg = log(d$Brain_Size_Species_Mean)), interval = "prediction",
    level = 0.9)  
head(pi)

df <- cbind(df, pi)
names(df) <- c("x", "y", "yhat", "CIfit", "CIlwr", "CIupr", "PIfit", "PIlwr",
    "PIupr")
head(df)

colors <- c("PI" = "red", "CIfit" = "black", "CI" = "blue")
g <- ggplot(data = df, aes(x = x, y = y))+ geom_line(data = df, aes(x = x, y = PIlwr, colour = "PI")) + geom_line(data = df, aes(x = x, y = PIupr, colour = "PI")) + geom_point(alpha = 1/2) + geom_line(aes(x = x, y = CIfit, colour = "CIfit")) + geom_line(aes(x = x, y = CIlwr, colour = "CI")) + geom_line(aes(x = x, y = CIupr, colour = "CI")) + stat_regline_equation(label.x=1, label.y=6.45) +  stat_cor(aes(label=..rr.label..), label.x=1, label.y=6.2) + scale_color_manual(values = colors)
g

#Now let's look again at the 800gm predictions

#point estimate:
predict(llm, newdata = data.frame(brainlg = log(800)))

#calculate predictions of confidence intervals
ci <- predict(llm, newdata = data.frame( brainlg = log(800)), interval = "confidence",
    level = 0.9)  ## confidence interval for a single value(800)
ci #these don't work for some reason? *C: I was having trouble with this too, it only gave me the 95% conf interval, so not sure how to solve this unfortunately but interesting to see we are running into similary issues.

#calculate prediction intervals
pi <- predict(llm, newdata = data.frame(brainlg = log(800)), interval = "prediction",
    level = 0.9) 
pi#these don't work for some reason? 

```
In comparing the two model's, I would be much more likely to trust the prediction from the log model. Not only is the r^2 value higher, but all of the values are more centralized so 6.68 is way more within the range of some of the data than in the previous model. Also, the Ci bands are much tigher in this model. 




*C: You did such an excellent job with all of this considering the challenge it gave all of us. Your code is clear, concise, and seems to work relatively smoothly as well. I am sorry if my comments were not super helpful in adding much, as I had trouble with this assignment but I think you really met most of the goals despite the obstacles still faced. Great job!
Challenges:

1. Figuring out how to do confidence intervals for each type is confusing
2.I still don't know how to do a point estimate or how to do the test hypotheses?
3.There are supposed to be two models, what are they, I'm very confused?