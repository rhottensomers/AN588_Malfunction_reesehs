---
title: "reesehs_OriginalHomeworkCode_04"
author: "Reese Hotten-Somers"
date: "2023-10-25"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(manipulate)
```

## Write a simple R function, Z.prop.test(), that can perform one- or two-sample Z-tests for proportion data, using the following guidelines:
```{r}

z.prop.test <- function( p1, n1, p2 = NULL, n2 = NULL, p0, alternative = c("two.sided", "less", "greater"), conf.levels = 0.95) {
  if(((n1*p1)> 5 )|| (n1*(1-p1) > 5)){
    print("non-normal distribution in one sample setting")
  }
  if((n2*p2)> 5 || n2*(1-p2) > 5){
    print("non-normal distribution in two sample setting")
  }
  if(is.null(p2) == TRUE || is.null(n2) == TRUE){
    z <- (p1-p0)/sqrt(p0 *(1-p0)/n1) #one sample z stat
    lower <- p1 - qnorm(0.95) * sqrt(p1 * (1 - p1)/n1)
    upper <- p1 + qnorm(0.95) * sqrt(p1 * (1 - p1)/n1)
    ci <- c(lower, upper) #confidence interval, is this correct?
    ci
    if(alternative == "two.sided"){
       p <- 1 - pnorm(z, lower.tail = TRUE) + pnorm(z, lower.tail = FALSE) #two tailed p value
    }
    if(alternative == "less"){
      p <- pnorm(z, lower.tail = TRUE) #lower tailed p value
    }
    if(alternative == "greater"){
      p <- pnorm(z, lowertail = FALSE) #upper tail p value
    }
   
  }
  if(is.null(p2) == TRUE & is.null(n2) == TRUE){
   z <- (p1-p0)/sqrt(p0 *(1-p0)/n1) # one sample z stat
    if(alternative == "two.sided"){
       p <- 1 - pnorm(z, lower.tail = TRUE) + pnorm(z, lower.tail = FALSE)
    }
    if(alternative == "less"){
      p <- pnorm(z, lower.tail = TRUE)
    }
    if(alternative == "greater"){
      p <- pnorm(z, lowertail = FALSE)
    }
    lower <- p1 - qnorm(0.95) * sqrt(p1 * (1 - p1)/30)
    upper <- p1 + qnorm(0.95) * sqrt(p1 * (1 - p1)/30)
    ci <- c(lower, upper) #confidence interval, is this correct?
    ci
  }

  if(!is.null(p2) & !is.null(n2)){
    pstar <- ((p0)/(n1 + n2))
    z <- (p2 - p1 - p0)/sqrt((pstar * (1 - pstar)) * (1/n1) + (1/n2))
    p <- 1 - pnorm(z, lower.tail = TRUE) + pnorm(z, lower.tail = FALSE)
     
     upper <- (p1 -p2) + qnorm(0.95) + (sqrt((p1 * (1 - p1)/n1) + (p2 * (1-p2)/n2))) 
     lower <- (p1 -p2) - qnorm(0.95) + (sqrt((p1 * (1 - p1)/n1) + (p2 * (1-p2)/n2)))
     ci <- c(lower, upper)
   # I literally have no idea how to do CI for a two sample test, I have looked everywhere. 
  }
  list(z, p, ci)

  #unclear how to code this, any help would be much appreciated :')
  }
```

## The dataset from Kamilar and Cooper has in it a large number of variables related to life history and body size. For this exercise, the end aim is to fit a simple linear regression model to predict longevity (MaxLongevity_m) measured in months from speciesâ€™ brain size (Brain_Size_Species_Mean) measured in grams. Do the following for both longevity~brain size and log(longevity)~log(brain size):

```{r, preliminaries}
library(ggplot2)
library(curl)
f <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/master/AN588_Fall23/KamilarAndCooperData.csv") #imports data about zombies
d <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = FALSE)  #reads data and creates data frame from it
head(d) #returns data frame
```

### Fit the regression model and, using {ggplot2}, produce a scatterplot with the fitted line superimposed upon the data. Append the the fitted model equation to your plot (HINT: use the function geom_text()).
```{r, regression model}
nl <- lm(data = d, MaxLongevity_m~Brain_Size_Species_Mean)
summary(nl)
g <- ggplot(data = d, aes(x = Brain_Size_Species_Mean, y = MaxLongevity_m)) + geom_point() + geom_smooth(method = "lm", formula = y ~ x) #need to add legend
g



beta1 <- cor(d$MaxLongevity_m, d$Brain_Size_Species_Mean, use = "complete.obs") * sd(d$MaxLongevity_m, na.rm = TRUE)/sd(d$Brain_Size_Species_Mean, na.rm = TRUE)
beta1

beta0 <- mean(d$MaxLongevity_m, na.rm = TRUE) - beta1 * mean(d$Brain_Size_Species_Mean, na.rm = TRUE)
beta0

#how are you supposed to take the 90 percent CI for slope/beta1?

ci <- confint(nl, level = 0.90)  # using the results of lm()
ci


ci <- predict(nl, newdata = data.frame(Brain_Size_Species_Mean = d$Brain_Size_Species_Mean), interval = "confidence",
    level = 0.95, )  # for a vector of values
head(ci)

df <- data.frame(ci)
head(df)



pe <- beta1 * 800 + beta0
pe #point estimate

h_hat <- predict(nl, newdata = data.frame(Brain_Size_Species_Mean = d$Brain_Size_Species_Mean))
df <- data.frame(cbind(d$Brain_Size_Species_Mean, d$MaxLongevity_m, h_hat))
names(df) <- c("x", "y", "yhat")
head(df)

ci <- predict(nl, newdata = data.frame(Brain_Size_Species_Mean = 800), interval = "confidence",
    level = 0.9)  # for a single value
ci

pi <- predict(nl, newdata = data.frame(Brain_Size_Species_Mean = 800), interval = "prediction",
    level = 0.9)  # for a single value
pi

ci <- predict(nl, newdata = data.frame(Brain_Size_Species_Mean = d$Brain_Size_Species_Mean), interval = "confidence",
    level = 0.9)  # for a vector of values
head(ci)

df <- cbind(df, ci)
names(df) <- c("x", "y", "yhat", "CIfit", "CIlwr", "CIupr")
head(df)


piBM <- predict(nl, newdata = data.frame(Brain_Size_Species_Mean = d$Brain_Size_Species_Mean), interval = "prediction",
    level = 0.9)  # for a vector of values
head(piBM)

df <- cbind(df, pi)
names(df) <- c("x", "y", "yhat", "CIfit", "CIlwr", "CIupr", "PIfit", "PIlwr",
    "PIupr")
head(df)


g <- ggplot(data = df, aes(x = x, y = y))+ geom_line(data = df, aes(x = x, y = PIlwr), colour = "red") + geom_line(data = df, aes(x = x, y = PIupr), colour = "red") + geom_point(alpha = 1/2) + geom_line(aes(x = x, y = CIfit), colour = "black") + geom_line(aes(x = x, y = CIlwr), colour = "blue") + geom_line(aes(x = x, y = CIupr), colour = "blue")
g

#when knit my PI doesn't map onto the graph the way it is supposed to, why??
```

```{r, make it a log}
llm <- lm(data = d, log(MaxLongevity_m)~log(Brain_Size_Species_Mean))
summary(llm)
lg <- ggplot(data = d, aes(x = log(MaxLongevity_m), y = log(Brain_Size_Species_Mean))) + geom_point() + geom_smooth(method = "lm", formula = y ~ x)
lg

beta1 <- cor(log(d$MaxLongevity_m), log(d$Brain_Size_Species_Mean), use = "complete.obs") * sd(log(d$MaxLongevity_m), na.rm = TRUE)/sd(log(d$Brain_Size_Species_Mean))
beta1

beta0 <- mean(log(d$MaxLongevity_m)) - beta1 * mean(log(d$Brain_Size_Species_Mean))
beta0

#how are you supposed to take the 90 percent CI for slope/beta1?

ci <- confint(nl, level = 0.90)  # using the results of lm(), confidence interval
ci

ci <- predict(nl, newdata = data.frame(Brain_Size_Species_Mean = log(d$Brain_Size_Species_Mean)), interval = "confidence",
    level = 0.95, )  # for a vector of values
head(ci) #ci overall

df <- data.frame(ci)
head(df)



pe <- beta1 * 800 + beta0
pe #point estimate

h_hat <- predict(nl, newdata = data.frame(Brain_Size_Species_Mean = log(d$Brain_Size_Species_Mean)))
df <- data.frame(cbind(log(d$Brain_Size_Species_Mean), log(d$MaxLongevity_m), h_hat))
names(df) <- c("x", "y", "yhat")
head(df)

ci <- predict(nl, newdata = data.frame(Brain_Size_Species_Mean = 800), interval = "confidence",
    level = 0.9)  # for a single value
ci

pi <- predict(nl, newdata = data.frame(Brain_Size_Species_Mean = 800), interval = "prediction",
    level = 0.9)  # for a single value
pi

ci <- predict(nl, newdata = data.frame(Brain_Size_Species_Mean = log(d$Brain_Size_Species_Mean)), interval = "confidence",
    level = 0.9)  # for a vector of values #this also only gives one value, whyyyy?
head(ci)

df <- cbind(df, ci)
names(df) <- c("x", "y", "yhat", "CIfit", "CIlwr", "CIupr")
head(df)



piBM <- predict(nl, newdata = data.frame(Brain_Size_Species_Mean = log(d$Brain_Size_Species_Mean)), interval = "prediction",
    level = 0.9)  # for a vector of values #this only give one value, why is that?
head(piBM)

df <- cbind(df, pi)
names(df) <- c("x", "y", "yhat", "CIfit", "CIlwr", "CIupr", "PIfit", "PIlwr",
    "PIupr")
head(df)


g <- ggplot(data = df, aes(x = x, y = y))+ geom_line(data = df, aes(x = x, y = PIlwr), colour = "red") + geom_line(data = df, aes(x = x, y = PIupr), colour = "red") + geom_point(alpha = 1/2) + geom_line(aes(x = x, y = CIfit), colour = "black") + geom_line(aes(x = x, y = CIlwr), colour = "blue") + geom_line(aes(x = x, y = CIupr), colour = "blue")
g
#what even happened?

```

Challenges:
1. Figuring out how to do confidence intervals for each type is confusing
2.I still don't know how to do a point estimate or how to do the test hypotheses?
3.There are supposed to be two models, what are they, I'm very confused?
